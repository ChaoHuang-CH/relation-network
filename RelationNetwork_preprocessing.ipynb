{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context와 question의 input size를 maximum에 맞추도록 masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# question, answer, context, label\n",
    "with open('./babi_preprocessd/train_dataset.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('./babi_preprocessd/val_dataset.pkl', 'rb') as f:\n",
    "    val = pickle.load(f)\n",
    "with open('./babi_preprocessd/test_dataset.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./babi_preprocessd/c_word_set.pkl', 'rb') as f:\n",
    "    c_word_set = pickle.load(f)\n",
    "with open('./babi_preprocessd/q_word_set.pkl', 'rb') as f:\n",
    "    q_word_set = pickle.load(f)\n",
    "with open('./babi_preprocessd/a_word_set.pkl', 'rb') as f:\n",
    "    a_word_set = pickle.load(f)\n",
    "with open('./babi_preprocessd/cqa_word_set.pkl', 'rb') as f:\n",
    "    cqa_word_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context word set #: 124\n",
      "question word set #: 88\n"
     ]
    }
   ],
   "source": [
    "print(\"context word set #: {}\".format(len(c_word_set)))\n",
    "print(\"question word set #: {}\".format(len(q_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_q, train_a, train_c, train_l] = train\n",
    "[val_q, val_a, val_c, val_l] = val\n",
    "[test_q, test_a, test_c, test_l] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_max_sent_len = 0\n",
    "for tc in train_c:\n",
    "    for context in tc:\n",
    "        if len(context) > c_max_sent_len:\n",
    "            c_max_sent_len = len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum words in one context sentence: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum words in one context sentence: {}\".format(c_max_sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_max_sent_len = 0\n",
    "for question in train_q:\n",
    "    if len(question) > q_max_sent_len:\n",
    "        q_max_sent_len = len(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum words in one question sentence: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum words in one question sentence: {}\".format(q_max_sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179909it [00:20, 8574.10it/s] \n"
     ]
    }
   ],
   "source": [
    "train_c_masked = []\n",
    "train_q_masked = []\n",
    "train_l_masked = []\n",
    "train_c_real_len = []\n",
    "train_q_real_len = []\n",
    "# cs: one context\n",
    "for cs, l, q in tqdm(zip(train_c, train_l, train_q)):\n",
    "    context_masked = []\n",
    "    context_real_length = []\n",
    "    # cs: many sentences\n",
    "    for context in cs:\n",
    "        context_real_length.append(len(context))\n",
    "        diff = c_max_sent_len - len(context)\n",
    "        if (diff > 0):\n",
    "            context_mask = np.append(context, [mask_index]*diff, axis=0)\n",
    "            context_masked.append(context_mask.tolist())\n",
    "        else:\n",
    "            context_masked.append(context)\n",
    "    diff_c = 20 - len(cs)\n",
    "    context_masked.extend([[0]*12]*diff_c)\n",
    "    train_c_masked.append(context_masked)\n",
    "\n",
    "    diff_q = q_max_sent_len - len(q)\n",
    "    train_q_real_len.append(len(q))\n",
    "    question_masked = np.array(np.append(q, [mask_index]*diff_q, axis=0))\n",
    "    train_q_masked.append(question_masked.tolist())\n",
    "    \n",
    "    diff_l = 20 - len(l)\n",
    "    label_masked = np.append(l, np.zeros((diff_l, 20)), axis= 0)\n",
    "    train_l_masked.append(label_masked.tolist())\n",
    "    context_real_length.extend([0]*diff_l)\n",
    "    train_c_real_len.append(context_real_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19907it [00:01, 12501.57it/s]\n"
     ]
    }
   ],
   "source": [
    "val_c_masked = []\n",
    "val_q_masked = []\n",
    "val_l_masked = []\n",
    "val_c_real_len = []\n",
    "val_q_real_len = []\n",
    "for cs, l, q in tqdm(zip(val_c, val_l, val_q)):\n",
    "    context_masked = []\n",
    "    context_real_length = []\n",
    "    for context in cs:\n",
    "        context_real_length.append(len(context))\n",
    "        diff = c_max_sent_len - len(context)\n",
    "        if (diff > 0):\n",
    "            context_mask = np.append(context, [mask_index]*diff, axis=0)\n",
    "            context_masked.append(context_mask.tolist())\n",
    "        else:\n",
    "            context_masked.append(context)\n",
    "    diff_c = 20 - len(cs)\n",
    "    context_masked.extend([[0]*12]*diff_c)\n",
    "    val_c_masked.append(context_masked)\n",
    "\n",
    "    diff_q = q_max_sent_len - len(q)\n",
    "    val_q_real_len.append(len(q))\n",
    "    question_masked = np.array(np.append(q, [mask_index]*diff_q, axis=0))\n",
    "    val_q_masked.append(question_masked.tolist())\n",
    "    \n",
    "    diff_l = 20 - len(l)\n",
    "    label_masked = np.append(l, np.zeros((diff_l, 20)), axis= 0)\n",
    "    val_l_masked.append(label_masked.tolist())\n",
    "    context_real_length.extend([0]*diff_l)\n",
    "    val_c_real_len.append(context_real_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19910it [00:01, 12484.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test_c_masked = []\n",
    "test_q_masked = []\n",
    "test_l_masked = []\n",
    "test_c_real_len = []\n",
    "test_q_real_len = []\n",
    "for cs, l, q in tqdm(zip(test_c, test_l, test_q)):\n",
    "    context_masked = []\n",
    "    context_real_length = []\n",
    "    for context in cs:\n",
    "        context_real_length.append(len(context))\n",
    "        diff = c_max_sent_len - len(context)\n",
    "        if (diff > 0):\n",
    "            context_mask = np.append(context, [mask_index]*diff, axis=0)\n",
    "            context_masked.append(context_mask.tolist())\n",
    "        else:\n",
    "            context_masked.append(context)\n",
    "    diff_c = 20 - len(cs)\n",
    "    context_masked.extend([[0]*12]*diff_c)\n",
    "    test_c_masked.append(context_masked)\n",
    "\n",
    "    diff_q = q_max_sent_len - len(q)\n",
    "    test_q_real_len.append(len(q))\n",
    "    question_masked = np.array(np.append(q, [mask_index]*diff_q, axis=0))\n",
    "    test_q_masked.append(question_masked.tolist())\n",
    "    \n",
    "    diff_l = 20 - len(l)\n",
    "    label_masked = np.append(l, np.zeros((diff_l, 20)), axis= 0)\n",
    "    test_l_masked.append(label_masked.tolist())\n",
    "    context_real_length.extend([0]*diff_l)\n",
    "    test_c_real_len.append(context_real_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179909it [00:01, 105004.32it/s]\n",
      "19907it [00:00, 102719.57it/s]\n",
      "19910it [00:00, 101863.47it/s]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for c,q,l in tqdm(zip(train_c_masked, train_q_masked, train_l_masked)):\n",
    "    for context in c:\n",
    "        if (len(context) != 12) | (len(q) != 12) | (len(l) != 20):\n",
    "            cnt += 1\n",
    "            \n",
    "for c,q,l in tqdm(zip(val_c_masked, val_q_masked, val_l_masked)):\n",
    "    for context in c:\n",
    "        if (len(context) != 12) | (len(q) != 12) | len(l) != 20:\n",
    "            cnt += 1\n",
    "            \n",
    "for c,q,l in tqdm(zip(test_c_masked, test_q_masked, test_l_masked)):\n",
    "    for context in c:\n",
    "        if (len(context) != 12) | (len(q) != 12) | len(l) != 20:\n",
    "            cnt += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking success!\n"
     ]
    }
   ],
   "source": [
    "if cnt == 0:\n",
    "    print(\"Masking success!\")\n",
    "else:\n",
    "    print(\"Masking process error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_masked = (train_q_masked, train_a, train_c_masked, train_l_masked, train_c_real_len, train_q_real_len)\n",
    "val_dataset_masked = (val_q_masked, val_a, val_c_masked, val_l_masked, val_c_real_len, val_q_real_len)\n",
    "test_dataset_masked = (test_q_masked, test_a, test_c_masked, test_l_masked, test_c_real_len, test_q_real_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./babi_preprocessd/train_dataset_masked.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dataset_masked, f)\n",
    "with open('./babi_preprocessd/val_dataset_masked.pkl', 'wb') as f:\n",
    "    pickle.dump(val_dataset_masked, f)\n",
    "with open('./babi_preprocessd/test_dataset_masked.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dataset_masked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
